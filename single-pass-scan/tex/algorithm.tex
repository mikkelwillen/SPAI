%high level description of the algorithm
For this project we attempt to implement the single-pass parallel prefix scan with decoupled look-back, as presented in \cite{spsArticle}.
The algorithm builds upon the chained-scan, which is also a single-pass scan.

\subsection{Chained-scan}
In the chained scan each thread is assigned a partition of $M$ elements to work on,
and the high-level description of the work of eac block can be explained in the following three steps:
\begin{enumerate}
  \item Each thread in the block reduce its $M$ elements, to find the partition aggregate, and from that the block aggregate is computed.
        If the block is the first block, this aggregate is published as the inclusive prefx of the block.
  \item The block wait for the previous block to have computed its inclusive prefix.
        When it recieves the value, it computes the block inclusive prefix and publishes it.
  \item Each thread now uses the block exclusive prefix to compute the scan of its $M$ elements.
\end{enumerate}
The problem with this approach is latency of signalling between thread blocks. \textbf{???}

This approach requires a block to wait patiently while the previous blocks compute their aggregates, and this part of the scan is thus sequential in that only one block at a time can compute theirinclusive prefix.
We would like to be able to parallelize the work further, and therefore we look at the \textit{single-pass parallel scan with decoupled look-back}.

\subsection{Single-pass parallel scan with decoupled look-back}
This algorithm ensures that a partition is not dependent on its immediate predecessor for the prefix result, and thus reduce the propagation latencies.
It works firstly by first of all not only publishing the block inclusive prefix when that is ready, but taking advantage of publication of the block aggregate to speed up the look-back.
This means that a block can check if the preceeding blocks have computed either the prefix or the aggregate, and if it finds a prefix it can stop searching, but if it finds an aggregate it can add that to its own exclusive prefix and keep on searching.

Secondly, it implements a parallel look-back where multiple threads can work together to find the block prefix,  and thus decrease the runtime.

The algorithm follows six steps:
\begin{enumerate}
  \item Initializing the partition descriptors. Each partition has a $flag$ which can be either $A$ if the aggregate has been computed, a $P$ if the prefix has been computed, or an $X$ if nothing has been computed yet.
        Furhtermore is has a value $A$ and $P$ which holds the aggregate and prefix (respectively) as soon as it has been computed.
        Both $A$ and $P$ is initialized to the neutral element, and the flag is initialized to $X$.
  \item In this step all processors syncronize, to ensure that all descriptors have been set appropriately.
  \item Now each processor computes the partition aggregate, publishes this, and sets its flag to $A$. If the partition is the very first partition, the prefix is also set, and the flag is set accordingly.
  \item Now the partition exclusive prefix is found by using the decoupled look-back.
        This is done by initialising a $block\_exclusive\_prefix$, and then fetching the flag of the predecessor and acting accordingly:
        \begin{itemize}
          \item If the flag is $X$, wait for the flag to change.
          \item If the flag is $A$, add the aggregate to the block\_exclusive\_prefix and loop again, looking at the next predecessor.
          \item If the flag is $P$ then add the prefix to the block\_exclusive\_prefix and stop looping.
        \end{itemize}
  \item Now the inclusive prefix for each partition is computed by adding the exclusive prefix to the aggregate, and setting the descriptor flag to $P$.
  \item Lastly, each partition computes the scan of its own elements again, but this time adding the exclusive prefix, and updating the values in global memory.
\end{enumerate}

Here we see that all steps can be computed in parallel, except for step 4, where a partition must wait for its predecessors to compute either the aggregate or inclusive prefix.
It is also important that we synchronize in step 2, so that all descriptors will be instantiated when the following steps are executed.
\\~\\
This algorithm should ensure some interesting properties, which makes it faster than other scans.
Firstly, the waiting time for each processor will be decreased, assuming that the system is relatively fair.
That means that each processor will have computed their aggregates in about the same amount of time, because of fair scheduling.
This also means that the aggregates are highly likely to be available to the processors when they are ready for computing their exclusive prefix.
Secondly, the look-back is bound by a constant, as there are a finite amount of predecessors that a processor will have to look at, and that the partitions are of constant size.
Thirdly, we have accelerated signal propagation. In the chained version, the publication of an inclusive prefix will stop the immediate decendent from waiting, however in this version it is possible that it releases all decendents from waiting.
